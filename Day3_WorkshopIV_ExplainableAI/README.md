# Tutorials for eXplainable Artificial Intelligence (XAI) methods

This repository contains a collection of self-explanatory tutorials for different model-agnostic and model-specific XAI methods.
Each tutorial comes in a Jupyter Notebook wich contains a short video lecture and practical exercises.

The learning objectives are:

- understand the importance of interpretability
- discover some of the existing model-agnostic and model-specific XAI methods
- learn how to interpret the outputs and graphs of those methods with hands-on exercises
- learn to chose which method is suitable for a specific task

## List of Tutorials for Model-Agnostic Methods

- Permutation Feature Importance
- SHapley Additive exPlanations (SHAP)

## List of Tutorials for Model-Specific Methods

- Forest-Guided Clustering

## Requirements and Setup

It is possible to either create an environment and install all the necessary packages locally (using the requirements.txt file) or to execute the notebooks on the browser, clicking the 'Open in Colab' button. This second option doesn't require any further installation, but the user must have acces to a Google account.
